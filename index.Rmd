---
title: "Exercise Quality Prediction for Pratical Machine Learning Course"
author: "Patrick Cormeau"
date: "November 17, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

The goal in this project is to use the data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants that were asked to perform barball lifts cottecly and incorrectly in 5 different ways to build a model able to predict the type, correctly or incorrectly,  of the performed activity.
More information about the experiment and the data used for this project are from the website http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset and the published paper by Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human â€™13). Stuttgart, Germany: ACM SIGCHI, 2013.).

The first step of the analysis is to read the data from the two supplied csv files.

```{r cars}
traindata <- read.csv("pml-training.csv", stringsAsFactors = FALSE )
testdata <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
```

Some of the variables are measured values but some of them are calculated values after a elapsed time. The calculated values are only available at certain point in time and the line containing them can be identified by the variable "new_window". When this variable has a value of "yes" (all other case the value is "no") the calculated values are available.

As the test dataset is based on measured value only, these calculated values are not usefull in our project (as no data are available for these in the test data). We will use the measuread values only for this analysis. We will also remove the variables for that are not measurements from the movements as the subject name and the timestamps.

```{r, message=FALSE, warning=FALSE}
library(dplyr)

traindatameas <- select(traindata, -starts_with("kurtosis"),
                                   -starts_with("skewness"),
                                   -starts_with("max"),
                                   -starts_with("min"),
                                   -starts_with("amplitude"),
                                   -starts_with("var"),
                                   -starts_with("avg"),
                                   -starts_with("stddev"),
                                   -X, -user_name,
                                   -contains("timestamp"),
                                   -contains("window")
                        )
traindatameas$classe <- factor(traindatameas$classe)
dim(traindatameas)
```

We now have 52 variables (53 - the "classe") for 19622 samples.

We are now removing highly correlated variables to improve the stability of the model
```{r, message=FALSE, warning=FALSE}
library(caret)

highCor <- findCorrelation(cor(traindatameas[,-53]), cutoff = 0.9, verbose = TRUE)
traindatameas <- traindatameas[,-highCor]
```

We can now train our model but we will keep some data to validate our model and use cross validation during the training.
```{r}
set.seed(1234)
part <- createDataPartition(y = traindatameas$classe, p = 0.7, list = FALSE)

trainmeas <- traindatameas[part,]
validmeas <- traindatameas[-part,]
```

We start by using Classification and regression trees using the rpart method:
```{r}
library(rpart)

mod <- train(classe ~ .,
             data = trainmeas,
             method = "rpart" ,
             trControl = trainControl(method = "cv", number = 4)
             )
pred <- predict(mod, trainmeas)
confusionMatrix(pred, trainmeas$classe)
```

THis model seriously lack accuracy even with the training data. We will try with a Random Forest method:
```{r, message=FALSE, warning=FALSE}
library(e1071)
library(ranger)
mod <- train(classe ~ .,
             data = trainmeas,
             method = "ranger",
             importance = "impurity"
             )
mod
mod$finalModel
```

There is no need to perform a cross validation on Random Forest. The validation set in not required either but we used it to assess the precision of our model. (http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr).

```{r}
pred <- predict(mod, validmeas)
confusionMatrix(pred, validmeas$classe)
```

The model is quite accurate with an accuracy of 99.5%. The out-of-bag (oob) error estimate is already computed during the model creation:

```{r}
round(mod$finalModel$prediction.error * 100, 2)
```

With 0.66% the error is quite small. The Random Forest gives a good model that should be able to predict the classe of the activity with a good precision.